{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from tensorflow import keras, convert_to_tensor\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP object creation :\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\", \"ner\"])  # disabling a few components should speed us up a bit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading cleaned dataset, using pickle allows type preservation (spacy doc, np array etc.)\n",
    "\n",
    "df = pd.read_pickle(filepath_or_buffer=\"../data/ecommerce_cleaned.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>doc_desc</th>\n",
       "      <th>lem_desc</th>\n",
       "      <th>first_category</th>\n",
       "      <th>product_specifications</th>\n",
       "      <th>image</th>\n",
       "      <th>description</th>\n",
       "      <th>category_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elegance Polyester Multicolor Abstract Eyelet ...</td>\n",
       "      <td>(key, elegance, polyester, multicolor, abstrac...</td>\n",
       "      <td>[key, elegance, polyester, multicolor, abstrac...</td>\n",
       "      <td>home furnishing</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>Key Features of Elegance Polyester Multicolor ...</td>\n",
       "      <td>[Home Furnishing, Curtains &amp; Accessories, Curt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  \\\n",
       "0  Elegance Polyester Multicolor Abstract Eyelet ...   \n",
       "\n",
       "                                            doc_desc  \\\n",
       "0  (key, elegance, polyester, multicolor, abstrac...   \n",
       "\n",
       "                                            lem_desc   first_category  \\\n",
       "0  [key, elegance, polyester, multicolor, abstrac...  home furnishing   \n",
       "\n",
       "                              product_specifications  \\\n",
       "0  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...   \n",
       "\n",
       "                                  image  \\\n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7.jpg   \n",
       "\n",
       "                                         description  \\\n",
       "0  Key Features of Elegance Polyester Multicolor ...   \n",
       "\n",
       "                                       category_tree  \n",
       "0  [Home Furnishing, Curtains & Accessories, Curt...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_name', 'doc_desc', 'lem_desc', 'first_category',\n",
       "       'product_specifications', 'image', 'description', 'category_tree'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = [\"lem_desc\", \"first_category\"]\n",
    "df_model = df[model_columns].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_str(row):\n",
    "    \"\"\"\n",
    "    Turns lem_desc, a list of tokens, into a string for CV and TF-IDF usage,\n",
    "    returns string\n",
    "    \"\"\"\n",
    "    desc_list = row[\"lem_desc\"]\n",
    "    desc_txt = \" \".join(desc_list)\n",
    "    return desc_txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.rename(columns={\"first_category\": \"category\"}, inplace=True)\n",
    "\n",
    "df_model[\"desc\"] = df_model.apply(list_to_str, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df_model[\"enc_category\"] = le.fit_transform(df_model[\"category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1024.00000\n",
       "mean       38.65918\n",
       "std        42.32380\n",
       "min         3.00000\n",
       "25%         9.00000\n",
       "50%        19.00000\n",
       "75%        58.00000\n",
       "max       272.00000\n",
       "Name: desc_size, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the average lenght of the lists of token in lem_desc to adapt tensor size :\n",
    "\n",
    "def get_desc_len(row):\n",
    "    return int(len(row[\"lem_desc\"]))\n",
    "\n",
    "\n",
    "df_model[\"desc_size\"] = df_model.apply(func=get_desc_len, axis=1)\n",
    "\n",
    "df_model[\"desc_size\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting before tokenizing :\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_model[\"desc\"],\n",
    "    df_model[\"enc_category\"],\n",
    "    test_size=0.30,\n",
    "    random_state=123\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized = tokenizer.batch_encode_plus(\n",
    "    X_test.tolist(),\n",
    "    max_length=256,  # Reducing the default size of the tensor\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\",\n",
    "    truncation=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the min/q1/q3 and max of the description lenghts, lowering the tensor size to 256 might be faster without truncating too many descriptions and without too much unnecessary padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the training set :\n",
    "\n",
    "X_train_tokenized = tokenizer.batch_encode_plus(\n",
    "    X_train.tolist(),\n",
    "    max_length=256,  # Reducing the default size of the tensor\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\",\n",
    "    truncation=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking input tensors : (uncomment to check CLS and SEP (101 and 102))\n",
    "# X_train_tokenized[\"input_ids\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ins and outs tensors\n",
    "\n",
    "input_tensors = X_train_tokenized[\"input_ids\"]\n",
    "output_tensors = convert_to_tensor(y_train)\n",
    "\n",
    "unique_cat_count = df_model[\"enc_category\"].unique().__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "output_tensors = keras.utils.to_categorical(\n",
    "    output_tensors,\n",
    "    num_classes=unique_cat_count\n",
    "    )\n",
    "\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=unique_cat_count\n",
    "    )\n",
    "\n",
    "# Use the CategoricalCrossentropy loss function\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "metric = keras.metrics.Accuracy(\"accuracy\")\n",
    "\n",
    "bert_model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[metric]\n",
    ")\n",
    "\n",
    "# BERT Large ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 16:56:42.784995: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "time_fit_zero = time.perf_counter()\n",
    "\n",
    "bert_model.fit(input_tensors, output_tensors, epochs=20, verbose=1)\n",
    "\n",
    "time_fit_end = time.perf_counter()\n",
    "\n",
    "print(f\"Fitting took {time_fit_end - time_fit_zero} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = np.argmax(output_tensors, axis=1)\n",
    "\n",
    "# Print the original labels\n",
    "print(original_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensors = X_test_tokenized[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bert_model.predict(test_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test_labels = np.argmax(predictions[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, original_test_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f56a869c4daa215a59dfefe9df0caca71d11de3c8dc85895ad84467caf29dffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
